[
  {
    "question": "According to the adoption data cited in the module (e.g., the 2025 Stack Overflow Developer Survey), which metric most directly demonstrates that AI coding assistants are part of developers' daily workflows today?",
    "answers": [
      "51% of professional developers use AI tools daily.",
      "84% of developers use or plan to use AI tools.",
      "AI now generates over 30% of new code at major tech companies.",
      "GitHub Copilot counts 1.8M paid seats and 77K enterprise customers."
    ],
    "correct": "51% of professional developers use AI tools daily."
  },
  {
    "question": "Two teams describe how their AI coding tools behave when asked to 'migrate this service to the new authentication API.' Scenario A: 'The tool lists a plan, requests confirmation after each step, proposes small diffs for a few files, and leaves it to you to run tests and apply changes.' Scenario B: 'The tool proposes a plan, applies coordinated edits across the codebase and tests, executes the test suite, iterates on failures it detects, updates documentation, and opens a PR with a change summary.' Which scenario best represents Phase 3 (Agentic Automation)?",
    "answers": [
      "Scenario A only",
      "Scenario B only",
      "Both A and B",
      "Neither A nor B"
    ],
    "correct": "Scenario B only"
  },
  {
    "question": "According to the study materials, developers realize the reported 20-50% productivity gains from AI coding assistants only when which practice is followed?",
    "answers": [
      "Provide rich architectural context and file references in prompts",
      "Conduct disciplined critical review and verification of AI output",
      "Use an IDE-integrated assistant for production feature work",
      "Switch models based on task complexity and context size"
    ],
    "correct": "Conduct disciplined critical review and verification of AI output"
  },
  {
    "question": "When leveraging an AI assistant to refactor a microservice, which competency is least critical for you to perform personally?",
    "answers": [
      "Manual boilerplate authorship across multiple files",
      "Decomposing the work into clear, AI-manageable tasks",
      "Crafting prompts that include relevant project context",
      "Reviewing AI output for security, performance, and maintainability"
    ],
    "correct": "Manual boilerplate authorship across multiple files"
  },
  {
    "question": "What are the three distinct development environments where AI coding assistants operate?",
    "answers": [
      "Desktop, Mobile, and Cloud",
      "IDE-Integrated, CLI/Terminal, and Web-Based",
      "Local, Remote, and Hybrid",
      "Frontend, Backend, and Full-Stack"
    ],
    "correct": "IDE-Integrated, CLI/Terminal, and Web-Based"
  },
  {
    "question": "You must deliver a clickable prototype for tomorrow's stakeholder demo. Constraints: zero local setup, a live shareable URL, real-time collaboration during the review, and the ability to export code afterward to continue locally. According to the module's three-environment framework, which environment is the best fit?",
    "answers": [
      "IDE-integrated assistant",
      "CLI/terminal assistant",
      "Web-based development platform",
      "CLI assistant with file-edit capabilities"
    ],
    "correct": "Web-based development platform"
  },
  {
    "question": "You're triaging a production issue over SSH on a headless server. You need AI help while staying in the terminal, with no visual debugging, and you may turn the result into a script. Which task is best suited to a CLI/terminal AI assistant?",
    "answers": [
      "Analyze rotating logs to surface recurring errors and propose safe grep/awk filters as a reusable shell snippet.",
      "Coordinate a cross-file refactor with continuous test execution and inline review of proposed edits.",
      "Create an interactive prototype in a zero-setup workspace with instant browser previews and shared comments.",
      "Diagnose a flaky test by stepping through execution and inspecting runtime state while comparing code changes."
    ],
    "correct": "Analyze rotating logs to surface recurring errors and propose safe grep/awk filters as a reusable shell snippet."
  },
  {
    "question": "You need an IDE that enables complex multi-file refactoring by giving the AI deep, project-wide context. According to the study materials, which description best matches the tool designed for this requirement?",
    "answers": [
      "A VS Code fork rebuilt to give AI deep, project-wide context for coordinated multi-file refactors",
      "A plugin for IntelliJ and VS Code with a Context Engine to overcome context limits in large microservice codebases",
      "An agentic code editor that plans tasks, runs code, and iteratively debugs to finish work in-editor",
      "A zero-setup browser IDE optimized for rapid prototyping, sharing, and collaboration"
    ],
    "correct": "A VS Code fork rebuilt to give AI deep, project-wide context for coordinated multi-file refactors"
  },
  {
    "question": "What is a key advantage of CLI/Terminal AI assistants?",
    "answers": [
      "Full access to project context and file structure",
      "Easy sharing and collaboration",
      "Scriptable and can be integrated into CI/CD pipelines",
      "Integrated deployment pipelines"
    ],
    "correct": "Scriptable and can be integrated into CI/CD pipelines"
  },
  {
    "question": "Which scenario is least appropriate for a web-based AI coding platform, given their typical strengths and limitations?",
    "answers": [
      "Ship a clickable MVP for stakeholders tomorrow, using mocked data and a shareable browser URL",
      "Refactor a complex legacy microservice requiring deep IDE debugging, broad multi-file edits, and local test execution",
      "Run a remote pair-programming session to prototype a small feature with zero setup and live collaboration",
      "Try a new framework in a temporary workspace to avoid installing local toolchains and configuration"
    ],
    "correct": "Refactor a complex legacy microservice requiring deep IDE debugging, broad multi-file edits, and local test execution"
  },
  {
    "question": "Before merging an AI-generated refactor of a microservice, which workflow best aligns with the module's recommended practice?",
    "answers": [
      "Merge when CI is green (tests pass); skip manual review to preserve speed",
      "Use detailed prompts and a stronger model; accept the AI diff unless staging exposes issues",
      "Iterate: generate changes, do human review (security, performance, maintainability), run/extend tests, refine, then merge",
      "Trust IDE assistants with full project context; reserve manual checks for public APIs and critical paths"
    ],
    "correct": "Iterate: generate changes, do human review (security, performance, maintainability), run/extend tests, refine, then merge"
  },
  {
    "question": "You must reason across a very large codebase and maintain long-context coherence. According to the module's model-selection guidance, which model is the best fit?",
    "answers": [
      "OpenAI's GPT-5",
      "Anthropic's Claude Opus",
      "Google's Gemini Pro",
      "OpenAI's o3"
    ],
    "correct": "Anthropic's Claude Opus"
  },
  {
    "question": "AI suggestions are drifting from your project's design decisions and verification practices. To keep outputs aligned without pasting long context in every prompt, which repository artifact should you add and maintain to brief the assistant?",
    "answers": [
      "AGENTS.md - repository guide for AI assistants with project context and rules",
      "AI_GUIDE.md - notes on prompts, model choices, and general tips for using AI",
      "ARCHITECTURE.md - high-level system design and component diagrams for developers",
      "STYLEGUIDE.md - code formatting and naming conventions enforced by tooling"
    ],
    "correct": "AGENTS.md - repository guide for AI assistants with project context and rules"
  },
  {
    "question": "Replace the vague request 'Fix this function: The Stripe webhook intermittently throws signature verification failed, runs on Vercel serverless, uses STRIPE_WEBHOOK_SECRET, and lives at @api/webhooks/stripe.ts.' Which rewritten prompt best follows the module's 'Context is Everything' guidance?",
    "answers": [
      "On Vercel serverless, @api/webhooks/stripe.ts intermittently throws 'signature verification failed'. Secret: STRIPE_WEBHOOK_SECRET. Diagnose likely causes (raw body/Stripe-Signature) and propose precise code fixes.",
      "@api/webhooks/stripe.ts reports 'signature verification failed' at times. Review and refactor for robustness with better logging and input validation; include tests.",
      "On Vercel serverless, Stripe webhook intermittently fails with 'signature verification failed'. Inspect raw body parsing and header handling; provide a patch and test plan.",
      "On Vercel serverless, @api/webhooks/stripe.ts is flaky in production. Refactor for reliability (retries/timeouts), add tests, and summarize changes."
    ],
    "correct": "On Vercel serverless, @api/webhooks/stripe.ts intermittently throws 'signature verification failed'. Secret: STRIPE_WEBHOOK_SECRET. Diagnose likely causes (raw body/Stripe-Signature) and propose precise code fixes."
  },
  {
    "question": "What is the primary reason vendors are moving from flat-rate to usage-based pricing when AI agents refactor across many files and update tests?",
    "answers": [
      "Agentic multi-step tasks use substantially more compute (tokens, runtime, tool calls) than simple completions",
      "Larger context windows and project-wide indexing make monthly costs too unpredictable under a flat plan",
      "Enterprises generally prefer metered billing that maps cleanly to internal budgets and chargebacks",
      "Heavy CLI usage increases token spend, so vendors meter terminal commands to control overall costs"
    ],
    "correct": "Agentic multi-step tasks use substantially more compute (tokens, runtime, tool calls) than simple completions"
  },
  {
    "question": "According to the module's privacy guidance for IDE-integrated assistants, what is the most appropriate first step before using one with proprietary code?",
    "answers": [
      "Verify the assistant's data handling and storage practices align with your organization's policies before enabling it.",
      "Choose an enterprise tier that advertises enhanced privacy controls; further review is generally unnecessary.",
      "Disable data retention and model-training features for your workspace to address privacy concerns.",
      "Assume processing remains local unless cloud features are explicitly turned on, and proceed."
    ],
    "correct": "Verify the assistant's data handling and storage practices align with your organization's policies before enabling it."
  },
  {
    "question": "According to the document, which tool's core feature is a 'Context Engine' designed to overcome context limitations for large-scale, complex codebases?",
    "answers": [
      "GitHub Copilot",
      "Cursor",
      "Augment",
      "Replit"
    ],
    "correct": "Augment"
  },
  {
    "question": "Based on Module 6's decision framework, choose the best environment for each task: refactoring a legacy service, writing deployment scripts, and building a quick MVP demo.",
    "answers": [
      "Refactor: IDE-integrated; Deployment scripts: CLI; MVP demo: Web-based",
      "Refactor: Web-based; Deployment scripts: IDE-integrated; MVP demo: CLI",
      "Refactor: IDE-integrated; Deployment scripts: IDE-integrated; MVP demo: Web-based",
      "Refactor: IDE-integrated; Deployment scripts: CLI; MVP demo: IDE-integrated"
    ],
    "correct": "Refactor: IDE-integrated; Deployment scripts: CLI; MVP demo: Web-based"
  }
]
